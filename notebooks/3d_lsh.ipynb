{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lsh.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvlF+48ZlMHLC+p7UoIpuf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibranfp/CursoDatosMasivosI/blob/main/notebooks/3d_lsh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdUGGucRbHND"
      },
      "source": [
        "# Búsqueda del vecino más cercano aproximado mediante funciones _hash_ sensibles a la localidad\n",
        "En esta libreta se realiza un buscador del vecino más cercano aproximado usando funciones _hash_ sensibles a la localidad (LSH). Especificamente, se define la familia LSH basada  en distribuciones $p$-estables para distancias $\\ell_1$ y $\\ell_2$ y otra familia para la distancia angular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp0vDo8kmXQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dda7fff-0a71-4365-9293-52d9fcb6c10a"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import struct\n",
        "import os \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import hog\n",
        "from skimage import data, exposure\n",
        "from skimage import io, transform\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import nltk\n",
        "nltk.download(['punkt','averaged_perceptron_tagger','wordnet'])\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus.reader.wordnet import NOUN, VERB, ADV, ADJ"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Wvgq06cYGm"
      },
      "source": [
        "## Conjunto de datos\n",
        "Para evaluar el buscador vamos usar el conjunto de vectores SIFT [ANN_SIFT10K](http://corpus-texmex.irisa.fr/) del grupo TEXMEX, el cual descargamos y extraemos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc2odYXEjxut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3251dd89-bc7f-41bd-b4ca-01aec73555bd"
      },
      "source": [
        "!wget -q ftp://ftp.irisa.fr/local/texmex/corpus/siftsmall.tar.gz\n",
        "!tar xvzf siftsmall.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "siftsmall/\n",
            "siftsmall/siftsmall_base.fvecs\n",
            "siftsmall/siftsmall_groundtruth.ivecs\n",
            "siftsmall/siftsmall_learn.fvecs\n",
            "siftsmall/siftsmall_query.fvecs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcCrqcSsdPq9"
      },
      "source": [
        "Definimos una función para leer los vectores de un archivo `.fvecs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A21yFipGn27r"
      },
      "source": [
        "import struct\n",
        "import os \n",
        "\n",
        "def lee_fvecs(ruta):\n",
        "  with open(ruta, 'rb') as f:\n",
        "    d = struct.unpack('i', f.read(4))[0]\n",
        "    n = f.seek(0, os.SEEK_END) // (4 + 4 * d)\n",
        "    f.seek(0)\n",
        "    vecs = np.zeros((n, d))\n",
        "    for i in range(n):\n",
        "      f.read(4)\n",
        "      vecs[i] = struct.unpack('f' * d, f.read(d * 4))\n",
        "  \n",
        "  return vecs "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idVajqxIdYhc"
      },
      "source": [
        "Leemos el conjunto de vectores base y consulta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dVRDdDsG8ua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdd29c9-dba8-4b3b-da79-af3e678c2b79"
      },
      "source": [
        "base = lee_fvecs('siftsmall/siftsmall_base.fvecs')\n",
        "consultas = lee_fvecs('siftsmall/siftsmall_query.fvecs')\n",
        "\n",
        "print('Base: {0} Consultas: {1}'.format(base.shape, consultas.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base: (10000, 128) Consultas: (100, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMp9OQTJddXL"
      },
      "source": [
        "Definimos una función para leer los vectores más cercanos reales (_groundtruth_) de un archivo `.ivecs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtJ_pLDXHy1L"
      },
      "source": [
        "def lee_ivecs(ruta):\n",
        "  with open(ruta, 'rb') as f:\n",
        "    d = struct.unpack('i', f.read(4))[0]\n",
        "    n = f.seek(0, os.SEEK_END) // (4 + 4 * d)\n",
        "    f.seek(0)\n",
        "    vecs = np.zeros((n, d), dtype=np.int)\n",
        "    for i in range(n):\n",
        "      f.read(4)\n",
        "      vecs[i] = struct.unpack('i' * d, f.read(d * 4))\n",
        "  \n",
        "  return vecs "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URIfS7yYdwji"
      },
      "source": [
        "Leemos estos vectores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2njOGnqI1N1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e00278f-7d25-478f-f99e-c202e4e2e01b"
      },
      "source": [
        "gt = lee_ivecs('siftsmall/siftsmall_groundtruth.ivecs')\n",
        "print('Groundtruth: {0}'.format(gt.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Groundtruth: (100, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4RtFE5QdzYm"
      },
      "source": [
        "## Distancias $\\ell_1$ y $\\ell_2$.\n",
        "Definimos nuestra clase de tabla _hash_ con una familia de funciones basada en distribuciones $s$-estables. En esta familia se elige aleatoriamente una proyección de $\\mathbb{R}^d$ sobre una línea, se desplaza por $b$ y se corta en segmentos de tamaño $w$, esto es,\n",
        "        $$\n",
        "        h_{\\mathbf{a},b} = \\left\\lfloor  \\frac{\\mathbf{a} \\cdot \\mathbf{x} + b}{w} \\right\\rfloor\n",
        "        $$\n",
        "donde $b \\in [0, w)$\n",
        "\n",
        " * Si $\\mathbf{a}$ se muestrea de una distribución normal se obtiene una familia LSH para distancia $\\ell_2$.\\newline\n",
        " * Si $\\mathbf{a}$ se muestrea de una distribución de Cauchy se obtiene una familia LSH para distancia $\\ell_1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc1K6B1MQSNk"
      },
      "source": [
        "class TablaLpLSH:\n",
        "  def __init__(self, n_cubetas, t_tupla, dim, width=4, norma = 'l2'):\n",
        "    self.n_cubetas = n_cubetas\n",
        "    self.tabla = [[] for i in range(n_cubetas)]\n",
        "    self.t_tupla = t_tupla\n",
        "    self.dim = dim\n",
        "    self.w = width\n",
        "\n",
        "    if norma == 'l2':\n",
        "      self.Amat = np.random.standard_normal((t_tupla, dim))\n",
        "    elif norma == 'l1':\n",
        "      self.Amat = np.random.standard_cauchy((t_tupla, dim))\n",
        "\n",
        "    self.bvec = np.random.uniform(low=0, high=self.w, size=t_tupla)\n",
        "    self.a = np.random.randint(0, np.iinfo(np.int32).max, size=self.t_tupla)\n",
        "    self.b = np.random.randint(0, np.iinfo(np.int32).max, size=self.t_tupla)\n",
        "    self.primo = 4294967291\n",
        "\n",
        "  def __repr__(self):\n",
        "    contenido = ['%d::%s' % (i, self.tabla[i]) for i in range(self.n_cubetas)]\n",
        "    return \"<TablaHash :%s >\" % ('\\n'.join(contenido))\n",
        "\n",
        "  def __str__(self):\n",
        "    contenido = ['%d::%s' % (i, self.tabla[i]) for i in range(self.n_cubetas) if self.tabla[i]]\n",
        "    return '\\n'.join(contenido)\n",
        "\n",
        "  def sl(self, x, i):\n",
        "    return (self.h(x) + i) % self.n_cubetas\n",
        "\n",
        "  def h(self, x):\n",
        "    return x % self.primo\n",
        "\n",
        "  def lphash(self, x):\n",
        "    prod = np.floor((self.Amat @ x.T + self.bvec) / self.w).astype(np.uint)\n",
        "    return np.sum(self.a * prod, dtype=np.ulonglong), np.sum(self.b * prod, dtype=np.ulonglong)\n",
        "     \n",
        "  def insertar(self, x, ident):\n",
        "    lph, v2 = self.lphash(x)\n",
        "\n",
        "    llena = True\n",
        "    for i in range(self.n_cubetas):\n",
        "      cubeta = int(self.sl(v2, i))\n",
        "      if not self.tabla[cubeta]:\n",
        "        self.tabla[cubeta].append(lph)\n",
        "        self.tabla[cubeta].append([ident])\n",
        "        llena = False\n",
        "        break\n",
        "      elif self.tabla[cubeta][0] == lph:\n",
        "        self.tabla[cubeta][1].append(ident)\n",
        "        llena = False\n",
        "        break\n",
        "\n",
        "    if llena:\n",
        "      print('¡Error, tabla llena!')\n",
        "\n",
        "  def buscar(self, x):\n",
        "    mh, v2 = self.lphash(x)\n",
        "\n",
        "    for i in range(self.n_cubetas):\n",
        "      cubeta = int(self.sl(v2, i))\n",
        "      if not self.tabla[cubeta]:\n",
        "        return []\n",
        "      elif self.tabla[cubeta][0] == mh:\n",
        "        return self.tabla[cubeta][1]\n",
        "        \n",
        "    return []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdEgt1NZd_J5"
      },
      "source": [
        "Instanciamos las tablas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gah2U0HDjezy"
      },
      "source": [
        "n_tablas = 30\n",
        "dim = base.shape[1]\n",
        "tablas = [TablaLpLSH(2**14, 3, dim, 4.0, 'l2') for _ in range(n_tablas)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq5d8JpseClV"
      },
      "source": [
        "Insertamos los vectores en cada tabla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-7H_zh8ji__"
      },
      "source": [
        "for i,x in enumerate(base):\n",
        "  for t in range(n_tablas):\n",
        "    tablas[t].insertar(x, i)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXT__NpoeGnJ"
      },
      "source": [
        "Realizamos la búsqueda de los vectores de consulta y recuperamos los vectores más similares del conjunto base."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muvQIHOcjmy2"
      },
      "source": [
        "vecs = []\n",
        "for i,q in enumerate(consultas):\n",
        "  dc = []\n",
        "  for t in range(n_tablas):\n",
        "      dc.extend(tablas[t].buscar(q))\n",
        "  vecs.append(set(dc))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0lg4Em1eLLD"
      },
      "source": [
        "Calculamos la distancia euclidiana entre cada vector de consulta y sus correspondientes vectores recuperados y los ordenamos por distancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZyA31aXjo-J"
      },
      "source": [
        "def distancia_euclidiana(x, y):   \n",
        "  return np.sqrt(np.sum((x - y)**2))\n",
        "\n",
        "def fuerza_bruta(ds, qs, fd):\n",
        "  medidas = np.zeros(ds.shape[0])\n",
        "  for i,x in enumerate(ds):\n",
        "    medidas[i] = fd(qs, x)\n",
        "\n",
        "  return np.sort(medidas), np.argsort(medidas)\n",
        "\n",
        "dists = []\n",
        "orden = []\n",
        "for i,q in enumerate(consultas):\n",
        "  ld = list(vecs[i])\n",
        "  if ld:\n",
        "    m,o = fuerza_bruta(base[ld], q, distancia_euclidiana)\n",
        "    dists.append(m)\n",
        "    orden.append([ld[e] for e in o])\n",
        "  else:\n",
        "    dists.append([])\n",
        "    orden.append([])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCJtOHB3ebuW"
      },
      "source": [
        "Extraemos los vecinos más cercanos encontrados por LSH y los reales y los comparamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24gZNDZLSpkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347f3607-559e-4ddb-da4d-d5c7b6bf555b"
      },
      "source": [
        "vmc_lsh = [o[0] if o else -1 for o in orden]\n",
        "vmc_real = [g[0] for g in gt]\n",
        "correcto = [vmc_lsh[i] == vmc_real[i] for i in range(len(vmc_lsh))]\n",
        "print('Promedio encontrados = {0}'.format(np.mean(correcto)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Promedio encontrados = 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5nTnkJmfBHm"
      },
      "source": [
        "## Distancia angular\n",
        "Definimos una clase de tabla LSH para distancia angular $ 1 - \\theta(\\mathbf{x}^{(i)}, \\mathbf{x}^{(j)})$  basada en la siguiente familia \n",
        "$$\n",
        "h_\\mathbf{v}(\\mathbf{x}^{(i)}) = signo(\\mathbf{v} \\cdot \\mathbf{x}^{(i)})\n",
        "$$\n",
        "\n",
        "donde $\\mathbf{v} \\in \\mathbb{R}^d$ es un vector aleatorio de tamaño unitario y\n",
        "\n",
        " $$\n",
        "\\theta(\\mathbf{x}^{(i)}, \\mathbf{x}^{(j)}) = \\arccos{\\left(\\frac{\\mathbf{x}^{(i)} \\cdot \\mathbf{x}^{(j)}}{\\lVert \\mathbf{x}^{(i)}\\rVert \\cdot \\lVert {\\mathbf{x}^{(j)}}\\rVert}\\right)}\n",
        "$$\n",
        "\n",
        "La probabilidad de que cualquier par de vectores $(\\mathbf{x}^{(i)}, \\mathbf{x}^{(j)})$ tenga un valor idéntico para esta familia es\n",
        "$$\n",
        "Pr[h_\\mathbf{v}(\\mathbf{x}^{(i)}) = h_\\mathbf{v}(\\mathbf{x}^{(j)}] = 1 - \\frac{\\theta(\\mathbf{x}^{(i)}, \\mathbf{x}^{(j)})}{\\pi}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6r-uoD0fJsY"
      },
      "source": [
        "class TablaCos:\n",
        "  def __init__(self, n_cubetas, t_tupla, dim):\n",
        "    self.n_cubetas = n_cubetas\n",
        "    self.tabla = [[] for i in range(n_cubetas)]\n",
        "    self.t_tupla = t_tupla\n",
        "    self.dim = dim\n",
        "\n",
        "    self.Amat = np.random.standard_normal((t_tupla, dim))\n",
        "    self.Amat /= np.linalg.norm(self.Amat, axis=1).reshape(-1, 1)\n",
        "    self.a = np.random.randint(0, np.iinfo(np.int32).max, size=self.t_tupla)\n",
        "    self.b = np.random.randint(0, np.iinfo(np.int32).max, size=self.t_tupla)\n",
        "    self.primo = 4294967291\n",
        "\n",
        "  def __repr__(self):\n",
        "    contenido = ['%d::%s' % (i, self.tabla[i]) for i in range(self.n_cubetas)]\n",
        "    return \"<TablaHash :%s >\" % ('\\n'.join(contenido))\n",
        "\n",
        "  def __str__(self):\n",
        "    contenido = ['%d::%s' % (i, self.tabla[i]) for i in range(self.n_cubetas) if self.tabla[i]]\n",
        "    return '\\n'.join(contenido)\n",
        "\n",
        "  def sl(self, x, i):\n",
        "    return (self.h(x) + i) % self.n_cubetas\n",
        "\n",
        "  def h(self, x):\n",
        "    return x % self.primo\n",
        "\n",
        "  def coshash(self, x):\n",
        "    sign = np.sign(self.Amat @ x.T).astype(np.uint)\n",
        "    return np.sum(self.a * sign, dtype=np.ulonglong), np.sum(self.b * sign, dtype=np.ulonglong)\n",
        "     \n",
        "  def insertar(self, x, ident):\n",
        "    ch, v2 = self.coshash(x)\n",
        "\n",
        "    llena = True\n",
        "    for i in range(self.n_cubetas):\n",
        "      cubeta = int(self.sl(v2, i))\n",
        "      if not self.tabla[cubeta]:\n",
        "        self.tabla[cubeta].append(ch)\n",
        "        self.tabla[cubeta].append([ident])\n",
        "        llena = False\n",
        "        break\n",
        "      elif self.tabla[cubeta][0] == ch:\n",
        "        self.tabla[cubeta][1].append(ident)\n",
        "        llena = False\n",
        "        break\n",
        "\n",
        "    if llena:\n",
        "      print('¡Error, tabla llena!')\n",
        "\n",
        "  def buscar(self, x):\n",
        "    ch, v2 = self.coshash(x)\n",
        "\n",
        "    for i in range(self.n_cubetas):\n",
        "      cubeta = int(self.sl(v2, i))\n",
        "      if not self.tabla[cubeta]:\n",
        "        return []\n",
        "      elif self.tabla[cubeta][0] == ch:\n",
        "        return self.tabla[cubeta][1]\n",
        "        \n",
        "    return []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mk75GpBoyGW"
      },
      "source": [
        "Instanciamos nuestras tablas para la distancia angular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzmYtp6QpVeW"
      },
      "source": [
        "n_tablas_cos = 30\n",
        "tablas_cos = [TablaCos(2**14, 3, dim) for _ in range(n_tablas_cos)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QgyDGZ3o2IN"
      },
      "source": [
        "Insertamos todos los vectores en cada tabla"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu6-ZXznp_xI"
      },
      "source": [
        "for i,x in enumerate(base):\n",
        "  for t in range(n_tablas_cos):\n",
        "    tablas_cos[t].insertar(x, i)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oMIPlD4o7wN"
      },
      "source": [
        "Realizamos la búsqueda de todos vectores de consulta en cada tabla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VkvfN9wqG_H"
      },
      "source": [
        "vecs_cos = []\n",
        "for i,q in enumerate(consultas):\n",
        "  dc_cos = []\n",
        "  for t in range(n_tablas_cos):\n",
        "      dc_cos.extend(tablas_cos[t].buscar(q))\n",
        "  vecs_cos.append(set(dc_cos))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78EKHeZCpErN"
      },
      "source": [
        "Definimos una función para calcular la similitud coseno, definida por \n",
        "\n",
        "$$\n",
        "S_{C}(\\mathbf{x}^{(i)}, \\mathbf{x}^{(j)}) = \\frac{\\mathbf{x}^{(i)} \\cdot \\mathbf{x}^{(j)}}{\\lVert \\mathbf{x}^{(i)}\\rVert \\cdot \\lVert \\mathbf{x}^{(j)} \\rVert} \n",
        "$$\n",
        "\n",
        "Calculamos la distancia coseno entre cada consulta y los vectores recuperados de las tablas, los cuales se ordenan por su similitud con el vector de consulta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhFLjy74gTCk"
      },
      "source": [
        "def similitud_coseno(x, y):\n",
        "  pnorma = (np.sqrt(x @ x) * np.sqrt(y @ y))\n",
        "\n",
        "  if pnorma > 0:\n",
        "    return (x @ y) / pnorma\n",
        "  else: \n",
        "    return np.nan \n",
        "\n",
        "def fuerza_bruta_cos(ds, qs, fd):\n",
        "  medidas = np.zeros(ds.shape[0])\n",
        "  for i,x in enumerate(ds):\n",
        "    medidas[i] = fd(qs, x)\n",
        "\n",
        "  return np.sort(medidas)[::-1], np.argsort(medidas)[::-1]\n",
        "\n",
        "sims_cos = []\n",
        "orden_cos = []\n",
        "for i,q in enumerate(consultas):\n",
        "  ldc = list(vecs_cos[i])\n",
        "  if ldc:\n",
        "    mc,oc = fuerza_bruta_cos(base[ldc], q, similitud_coseno)\n",
        "    sims_cos.append(mc)\n",
        "    orden_cos.append([ldc[e] for e in oc])\n",
        "  else:\n",
        "    sims_cos.append([])\n",
        "    orden_cos.append([])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "771c_S80pVEM"
      },
      "source": [
        "Comparamos los vecinos más cercanos encontrados por LSH y los reales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAwXZTGgpmcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418e226f-a203-4407-a10a-ff9ab68de979"
      },
      "source": [
        "vmc_lshcos = [o[0] if o else -1 for o in orden_cos]\n",
        "vmc_real = [g[0] for g in gt]\n",
        "correctos_cos = [vmc_lshcos[i] == vmc_real[i] for i in range(len(vmc_lshcos))]\n",
        "print('Promedio encontrados = {0}'.format(np.mean(correctos_cos)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Promedio encontrados = 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVfVkovFsOqf"
      },
      "source": [
        "## Ejercicio\n",
        " * Compara el desempeño de los algoritmos usando distintos hiperparámetros\n",
        " * Usa otro conjunto de datos para evaluar los algoritmos"
      ]
    }
  ]
}